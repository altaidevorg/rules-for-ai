---
description: google-adk tutorial on InvocationContext, the per-turn context object holding session, services, agent, config, and state.
globs: src/google/adk/agents/invocation_context.py
alwaysApply: false
---
# Chapter 9: InvocationContext

In the [previous chapter](basellmflow.mdc), we explored `BaseLlmFlow`, the engine that orchestrates the complex interaction between an [Agent (BaseAgent / LlmAgent)](agent__baseagent___llmagent_.mdc) and the [BaseLlm](basellm.mdc), especially when handling [Tools (BaseTool)](tool__basetool_.mdc). We saw that the flow logic often needs access to the current session, services, agent configuration, and more. Passing all these elements individually down the call stack (Runner -> Agent -> Flow -> Processors -> Callbacks -> Tools) would be cumbersome and error-prone. This chapter introduces `InvocationContext`, the object designed to solve this by encapsulating all necessary information for a *single* agent turn (invocation).

## Motivation and Use Case

Consider a single turn initiated by a user message. Processing this message might involve:
*   Retrieving the [Session (Session / BaseSessionService)](session__session___basesessionservice_.mdc) history and [State](state.mdc).
*   Knowing which specific [Agent (BaseAgent / LlmAgent)](agent__baseagent___llmagent_.mdc) is currently active (especially in hierarchical setups).
*   Accessing services like `artifact_service` or `session_service`.
*   Applying runtime configurations (`RunConfig`).
*   Tracking unique identifiers for logging and tracing.
*   Signaling when the turn should end prematurely.

Instead of passing numerous parameters through every function call, `InvocationContext` acts as a "carrier" object. It bundles all this context together and is passed down through the execution hierarchy. This promotes cleaner code, ensures necessary information is available where needed without relying on global state, and simplifies the interfaces of core components like agents, flows, and tools.

**Central Use Case:** The [Runner](runner.mdc) receives a user message for a specific session.
1.  The `Runner` creates an `InvocationContext` instance, populating it with the fetched `Session`, references to the configured services (`session_service`, etc.), the root `agent`, the `user_content`, a unique `invocation_id`, and the `RunConfig`.
2.  The `Runner` determines the correct agent to run (e.g., `agent_A`) and calls `agent_A.run_async(invocation_context)`.
3.  Inside `agent_A`, if it needs to call a sub-agent (`agent_B`), it creates a *new* `InvocationContext` (usually a copy of the parent's, updating `agent` to `agent_B` and appending to `branch`) and calls `agent_B.run_async(sub_context)`.
4.  If `agent_B` (an `LlmAgent`) uses its internal [BaseLlmFlow](basellmflow.mdc), it passes its `InvocationContext` (`sub_context`) to the flow.
5.  If the flow triggers a [Tool (BaseTool)](tool__basetool_.mdc), it creates a [ToolContext](toolcontext.mdc) (which wraps the `InvocationContext`) and passes it to the tool's `run_async`.
6.  Throughout this flow, any component (agent, flow, tool, callback) can access, for example, `ctx.session.state` or `ctx.session_service` via the context object it received.

## Key Concepts

`InvocationContext` is primarily a data structure (a Pydantic `BaseModel`) holding references and state for a single `Runner.run_async` execution cycle.

*   **Service References:**
    *   `artifact_service`: Optional reference to the configured `BaseArtifactService`.
    *   `session_service`: Reference to the configured `BaseSessionService`.
    *   `memory_service`: Optional reference to the configured `BaseMemoryService`.
*   **Core Turn Information:**
    *   `session`: The actual [Session (Session / BaseSessionService)](session__session___basesessionservice_.mdc) object for the current conversation turn, including its `events` and `state`. (Readonly view often exposed via other contexts like `CallbackContext`).
    *   `agent`: The specific [Agent (BaseAgent / LlmAgent)](agent__baseagent___llmagent_.mdc) instance whose `run_async` or `run_live` method is currently being executed within this context. This changes as control passes down the agent hierarchy.
    *   `user_content`: The `google.genai.types.Content` object representing the user message that triggered this invocation.
*   **Runtime Configuration:**
    *   `run_config`: An instance of `RunConfig` providing parameters like streaming mode, max LLM calls, etc.
*   **Tracking and Identification:**
    *   `invocation_id`: A unique string identifier generated by the `Runner` for this specific turn/invocation. Useful for correlating logs and events belonging to the same user interaction cycle.
    *   `branch`: An optional string representing the path taken through the agent hierarchy (e.g., `root_agent.sub_agent_1.sub_sub_agent_A`). Automatically updated as context is passed down.
*   **Invocation Lifecycle State:**
    *   `end_invocation` (bool): A flag (default `False`) that can be set to `True` by callbacks or tools to signal that the current invocation should terminate immediately after the current step, preventing further LLM calls or processing within this turn.
    *   `live_request_queue`: Used in `run_live` mode to receive streaming inputs.
    *   `active_streaming_tools`: Dictionary tracking active streaming tools in `run_live` mode.
    *   `transcription_cache`: List used internally for caching data related to audio transcription in `run_live` mode.
*   **Cost Management (Internal):**
    *   `_invocation_cost_manager`: An internal object used to track metrics like the number of LLM calls made during the invocation, enforcing limits set in `RunConfig`.
*   **Computed Properties:**
    *   `app_name`: Convenience property to get `session.app_name`.
    *   `user_id`: Convenience property to get `session.user_id`.

## How to Use `InvocationContext`

You typically don't create `InvocationContext` instances yourself unless implementing custom runner or flow logic. As a developer building agents, tools, or callbacks, you receive the context as an argument.

1.  **Receiving the Context:**
    *   Agent methods (`_run_async_impl`, `_run_live_impl`): Receive `InvocationContext` directly.
    *   Callbacks (e.g., `before_model_callback`, `after_tool_callback`): Receive `CallbackContext`, which wraps `InvocationContext`.
    *   Tool execution (`run_async`): Receives [ToolContext](toolcontext.mdc), which also wraps `InvocationContext`.

2.  **Accessing Context Attributes (Example in a Callback):**

    ```python
    from google.adk.agents import CallbackContext, LlmRequest, LlmResponse
    from google.adk.sessions import State # For prefixes

    def my_before_model_callback(
        callback_context: CallbackContext, llm_request: LlmRequest
    ) -> Optional[LlmResponse]:

        # Access underlying InvocationContext via protected attribute
        ctx = callback_context._invocation_context

        print(f"Invocation ID: {ctx.invocation_id}")
        print(f"Current Agent: {ctx.agent.name}")
        print(f"Session ID: {ctx.session.id}")

        # Access session state via CallbackContext's state property
        user_name = callback_context.state.get(State.USER_PREFIX + "username")
        if user_name:
            print(f"User Name from State: {user_name}")

        # Access user message that started this turn
        if ctx.user_content and ctx.user_content.parts:
            print(f"Triggering User Text: {ctx.user_content.parts[0].text}")

        # Access services (e.g., to log something to the session)
        # Note: Be careful adding events directly here, usually done by Runner/Flow
        # ctx.session_service.append_event(...) # Generally avoid direct calls

        # Example: Force end the invocation based on some condition
        if "forbidden keyword" in llm_request.contents[-1].parts[0].text:
            print("Forbidden keyword detected, ending invocation.")
            ctx.end_invocation = True
            # Returning a response skips the LLM call
            return LlmResponse(content=types.Content(parts=[
                types.Part(text="Request blocked.")
            ]))

        # Return None to proceed with LLM call
        return None
    ```
    *Technical Explanation:* The callback receives `CallbackContext`. We access the underlying `InvocationContext` (`ctx`) to get `invocation_id`, `agent`, `session.id`, and `user_content`. Session state is accessed via `callback_context.state`, which handles delta tracking. Services like `session_service` are available on `ctx`, though direct use in callbacks needs care. The `ctx.end_invocation = True` flag signals termination.

3.  **Accessing Context in a Tool:**

    ```python
    from google.adk.tools import ToolContext, BaseTool
    from typing import Any

    class MySimpleTool(BaseTool):
        # ... name, description, _get_declaration ...

        async def run_async(
            self, *, args: dict[str, Any], tool_context: ToolContext
        ) -> Any:
            # Access underlying InvocationContext
            inv_ctx = tool_context._invocation_context

            print(f"Tool {self.name} running within Invocation: {inv_ctx.invocation_id}")
            print(f"Triggered by Agent: {inv_ctx.agent.name}")

            # Access RunConfig
            streaming_mode = inv_ctx.run_config.streaming_mode if inv_ctx.run_config else "Default"
            print(f"Streaming Mode: {streaming_mode}")

            # Use ToolContext to access state or save artifacts
            tool_context.state["tool_last_run"] = self.name
            # result = tool_context.load_artifact("input_data.csv")

            # Tool logic...
            return {"status": "completed"}
    ```
    *Technical Explanation:* Tools receive `ToolContext`. We access the underlying `InvocationContext` (`inv_ctx`) to read `invocation_id`, `agent.name`, and `run_config`. State modifications and artifact interactions typically use the methods provided by `ToolContext` itself (`tool_context.state`, `tool_context.load_artifact`).

## Internal Implementation

*   **Creation (`src/google/adk/runners.py`):** The `Runner` is responsible for creating the initial `InvocationContext` at the start of `run_async`.

    ```python
    # Simplified from Runner._new_invocation_context
    from .agents.invocation_context import InvocationContext, new_invocation_context_id
    # ... other imports ...

    class Runner:
        # ... __init__ ...
        def _new_invocation_context(
            self,
            session: Session,
            *,
            new_message: Optional[types.Content] = None,
            live_request_queue: Optional[LiveRequestQueue] = None,
            run_config: RunConfig = RunConfig(),
        ) -> InvocationContext:
            invocation_id = new_invocation_context_id() # Generate unique ID

            # Basic context initialization
            context = InvocationContext(
                artifact_service=self.artifact_service,
                session_service=self.session_service,
                memory_service=self.memory_service,
                invocation_id=invocation_id,
                agent=self.agent, # Initially set to root agent
                session=session,
                user_content=new_message,
                live_request_queue=live_request_queue,
                run_config=run_config,
                # branch starts as None/empty at the root
            )
            # ... potential logic for CFC/tool setup ...
            return context

        async def run_async(self, ...) -> AsyncGenerator[Event, None]:
            # ... get session ...
            invocation_context = self._new_invocation_context(
                session, new_message=new_message, run_config=run_config
            )
            # ... append user message ...
            invocation_context.agent = self._find_agent_to_run(session, self.agent) # Update agent
            async for event in invocation_context.agent.run_async(invocation_context): # Pass context
                # ... process event ...
                yield event
    ```
    *Technical Explanation:* `_new_invocation_context` gathers all necessary components (services, session, root agent, input, config) and instantiates `InvocationContext`, generating a unique `invocation_id`. The `run_async` method then calls the selected agent's `run_async`, passing this context object.

*   **Propagation (`src/google/adk/agents/base_agent.py`):** When an agent calls a sub-agent, it creates a derived context.

    ```python
    # Simplified from BaseAgent._create_invocation_context
    class BaseAgent(BaseModel):
        # ... name, sub_agents ...
        def _create_invocation_context(
            self, parent_context: InvocationContext
        ) -> InvocationContext:
            # Create a copy, updating the agent to 'self'
            invocation_context = parent_context.model_copy(update={'agent': self})
            # Update the branch information
            if parent_context.branch:
                invocation_context.branch = f'{parent_context.branch}.{self.name}'
            else:
                # Handle root case or if parent didn't have a branch set
                # (Could potentially start branch with self.name if needed)
                # Current implementation seems to inherit None if parent is None
                invocation_context.branch = self.name if self.parent_agent else None

            return invocation_context

        async def _run_async_impl(self, ctx: InvocationContext):
            # Example: Calling a sub_agent
            if self.sub_agents:
                sub_agent = self.sub_agents[0]
                # Create context specific to the sub_agent
                sub_agent_ctx = sub_agent._create_invocation_context(ctx)
                async for event in sub_agent.run_async(sub_agent_ctx):
                    yield event
            # ... other agent logic ...
    ```
    *Technical Explanation:* `_create_invocation_context` (called by the agent implementation, like in the example `_run_async_impl`) uses Pydantic's `model_copy` to duplicate the parent context and then updates the `agent` field to the current agent (`self`) and modifies the `branch` string to reflect the hierarchical path. This ensures sub-agents run with a context accurately reflecting their position and identity.

*   **Data Structure (`src/google/adk/agents/invocation_context.py`):**
    `InvocationContext` is a Pydantic `BaseModel`, providing type checking, validation, and serialization capabilities.

    ```python
    # Simplified from InvocationContext definition
    from pydantic import BaseModel, Field
    # ... other imports ...

    class InvocationContext(BaseModel):
        # ... model_config ...
        artifact_service: Optional[BaseArtifactService] = None
        session_service: BaseSessionService
        memory_service: Optional[BaseMemoryService] = None
        invocation_id: str
        branch: Optional[str] = None
        agent: BaseAgent
        user_content: Optional[types.Content] = None
        session: Session
        end_invocation: bool = False
        live_request_queue: Optional[LiveRequestQueue] = None
        # ... other fields (active_streaming_tools, transcription_cache, run_config) ...
        _invocation_cost_manager: _InvocationCostManager = Field(default_factory=_InvocationCostManager)

        # ... properties (app_name, user_id) ...
        # ... increment_llm_call_count method ...
    ```
    *Technical Explanation:* Defines the fields discussed in Key Concepts, leveraging Pydantic for structure and type hints.

*   **Sequence Diagram (Context Creation and Passing):**

    ```mermaid
    sequenceDiagram
        participant Runner
        participant RootAgent as Agent (Root)
        participant SubAgent as Agent (Sub)
        participant Flow as BaseLlmFlow
        participant Tool

        Runner->>Runner: _new_invocation_context(session, services, user_content, run_config)
        Runner-->>Runner: root_ctx (agent=RootAgent)
        Runner->>+RootAgent: run_async(root_ctx)
        RootAgent->>RootAgent: _create_invocation_context(root_ctx)
        RootAgent-->>RootAgent: sub_agent_ctx (agent=SubAgent, branch=RootAgent.SubAgent)
        RootAgent->>+SubAgent: run_async(sub_agent_ctx)
        SubAgent->>+Flow: run_async(sub_agent_ctx)  # Flow uses context
        Flow->>+Tool: run_async(args, tool_context) # ToolContext wraps sub_agent_ctx
        Tool-->>-Flow: result
        Flow-->>-SubAgent: yield event
        SubAgent-->>-RootAgent: yield event
        RootAgent-->>-Runner: yield event
    ```
    *Technical Explanation:* This diagram shows the `Runner` creating the initial context. When `RootAgent` decides to call `SubAgent`, `SubAgent` creates a derived context (`sub_agent_ctx`) before calling its `run_async`. This derived context is then passed down to the `Flow` and wrapped inside `ToolContext` for the `Tool`.

## Conclusion

`InvocationContext` is the essential carrier of information for a single agent turn within `google-adk`. It bundles references to core services, the current session, the specific agent being executed, user input, runtime configuration, and invocation-specific state like termination flags. By passing this context object down the call stack, the framework ensures that all components involved in processing a turn have access to the necessary information without resorting to global variables or complex parameter lists, thereby promoting encapsulation and modularity.

While `InvocationContext` provides the general context for the entire turn, tools often need a slightly more specialized view, particularly regarding their specific function call and authentication. The next chapter explores the [ToolContext](toolcontext.mdc), which builds upon `InvocationContext` to provide this tool-specific perspective.


---

Generated by [Rules for AI](https://github.com/altaidevorg/rules-for-ai)